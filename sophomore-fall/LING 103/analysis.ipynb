{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_clean_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and perform initial data cleaning\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    \n",
    "    # Convert categorical columns to categorical type\n",
    "    categorical_cols = ['register type', 'variant type', 'academic field', 'gender']\n",
    "    for col in categorical_cols:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_register_distribution(df):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of registers across different contexts\n",
    "    \"\"\"\n",
    "    register_dist = df['register type'].value_counts()\n",
    "    register_by_field = pd.crosstab(df['academic field'], df['register type'])\n",
    "    register_by_gender = pd.crosstab(df['gender'], df['register type'])\n",
    "    \n",
    "    return {\n",
    "        'overall_distribution': register_dist,\n",
    "        'by_field': register_by_field,\n",
    "        'by_gender': register_by_gender\n",
    "    }\n",
    "\n",
    "def analyze_variant_patterns(df):\n",
    "    \"\"\"\n",
    "    Analyze patterns in variant usage\n",
    "    \"\"\"\n",
    "    variant_dist = df['variant type'].value_counts()\n",
    "    variant_by_register = pd.crosstab(df['register type'], df['variant type'])\n",
    "    variant_by_field = pd.crosstab(df['academic field'], df['variant type'])\n",
    "    \n",
    "    return {\n",
    "        'overall_distribution': variant_dist,\n",
    "        'by_register': variant_by_register,\n",
    "        'by_field': variant_by_field\n",
    "    }\n",
    "\n",
    "def chi_square_test(df, var1, var2):\n",
    "    \"\"\"\n",
    "    Perform chi-square test of independence\n",
    "    \"\"\"\n",
    "    contingency_table = pd.crosstab(df[var1], df[var2])\n",
    "    chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    \n",
    "    return {\n",
    "        'chi2': chi2,\n",
    "        'p_value': p_value,\n",
    "        'dof': dof,\n",
    "        'contingency_table': contingency_table\n",
    "    }\n",
    "\n",
    "def analyze_usage_patterns(df):\n",
    "    \"\"\"\n",
    "    Analyze actual usage patterns and create frequency distributions\n",
    "    \"\"\"\n",
    "    # Group by register type and variant type to see common patterns\n",
    "    usage_patterns = df.groupby(['register type', 'variant type'])['actual usage'].value_counts()\n",
    "    \n",
    "    # Calculate type-token ratio for each register\n",
    "    ttr_by_register = {}\n",
    "    for register in df['register type'].unique():\n",
    "        register_tokens = df[df['register type'] == register]['actual usage']\n",
    "        types = len(set(register_tokens))\n",
    "        tokens = len(register_tokens)\n",
    "        ttr_by_register[register] = types / tokens if tokens > 0 else 0\n",
    "        \n",
    "    return {\n",
    "        'usage_patterns': usage_patterns,\n",
    "        'type_token_ratio': ttr_by_register\n",
    "    }\n",
    "\n",
    "def plot_distributions(df):\n",
    "    \"\"\"\n",
    "    Create visualizations of the data distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create multiple plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Plot 1: Register distribution\n",
    "    sns.countplot(data=df, x='register type', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Distribution of Registers')\n",
    "    axes[0,0].set_xlabel('Register Type')\n",
    "    axes[0,0].set_ylabel('Count')\n",
    "    \n",
    "    # Plot 2: Variant distribution by register\n",
    "    register_variant = pd.crosstab(df['register type'], df['variant type'])\n",
    "    register_variant.plot(kind='bar', stacked=True, ax=axes[0,1])\n",
    "    axes[0,1].set_title('Variant Distribution by Register')\n",
    "    axes[0,1].set_xlabel('Register Type')\n",
    "    axes[0,1].set_ylabel('Count')\n",
    "    \n",
    "    # Plot 3: Academic field distribution\n",
    "    sns.countplot(data=df, x='academic field', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Distribution by Academic Field')\n",
    "    axes[1,0].set_xticklabels(axes[1,0].get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 4: Gender distribution by register\n",
    "    gender_register = pd.crosstab(df['gender'], df['register type'])\n",
    "    gender_register.plot(kind='bar', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Register Distribution by Gender')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def generate_summary_statistics(df):\n",
    "    \"\"\"\n",
    "    Generate comprehensive summary statistics for the dataset\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input dataframe containing sociolinguistic data\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing various summary statistics organized by category\n",
    "    \"\"\"\n",
    "    summary_stats = {}\n",
    "    \n",
    "    # Overall dataset statistics\n",
    "    summary_stats['dataset_overview'] = {\n",
    "        'total_observations': len(df),\n",
    "        'unique_registers': df['register type'].nunique(),\n",
    "        'unique_variants': df['variant type'].nunique(),\n",
    "        'unique_fields': df['academic field'].nunique(),\n",
    "        'missing_values': df.isnull().sum().to_dict()\n",
    "    }\n",
    "    \n",
    "    # Register type statistics\n",
    "    register_stats = df.groupby('register type').agg({\n",
    "        'variant type': ['count', 'nunique'],\n",
    "        'actual usage': ['count', 'nunique']\n",
    "    })\n",
    "    register_stats.columns = ['total_occurrences', 'unique_variants', \n",
    "                            'usage_tokens', 'unique_usage_types']\n",
    "    summary_stats['register_statistics'] = register_stats.to_dict()\n",
    "    \n",
    "    # Calculate proportions for each categorical variable\n",
    "    categorical_cols = ['register type', 'variant type', 'academic field', 'gender']\n",
    "    proportions = {}\n",
    "    for col in categorical_cols:\n",
    "        prop = (df[col].value_counts() / len(df) * 100).round(2)\n",
    "        proportions[col] = prop.to_dict()\n",
    "    summary_stats['category_proportions'] = proportions\n",
    "    \n",
    "    # Cross-categorical analysis\n",
    "    summary_stats['cross_categorical'] = {\n",
    "        'register_by_field': pd.crosstab(\n",
    "            df['register type'], \n",
    "            df['academic field'], \n",
    "            normalize='index'\n",
    "        ).round(3).to_dict(),\n",
    "        'variant_by_register': pd.crosstab(\n",
    "            df['variant type'], \n",
    "            df['register type'], \n",
    "            normalize='index'\n",
    "        ).round(3).to_dict()\n",
    "    }\n",
    "    \n",
    "    # Usage pattern statistics\n",
    "    usage_stats = df.groupby('register type')['actual usage'].agg([\n",
    "        ('mean_usage_length', lambda x: x.str.len().mean()),\n",
    "        ('median_usage_length', lambda x: x.str.len().median()),\n",
    "        ('std_usage_length', lambda x: x.str.len().std()),\n",
    "        ('unique_usage_ratio', lambda x: len(set(x)) / len(x))\n",
    "    ]).round(3)\n",
    "    summary_stats['usage_statistics'] = usage_stats.to_dict()\n",
    "    \n",
    "    # Descriptive statistics for numerical features (if any)\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        summary_stats['numerical_statistics'] = df[numerical_cols].describe().to_dict()\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "def print_summary_report(summary_stats):\n",
    "    \"\"\"\n",
    "    Print a formatted report of the summary statistics\n",
    "    \n",
    "    Parameters:\n",
    "    summary_stats (dict): The dictionary containing summary statistics\n",
    "    \"\"\"\n",
    "    print(\"\\n=== SOCIOLINGUISTIC DATA ANALYSIS SUMMARY ===\\n\")\n",
    "    \n",
    "    # Dataset Overview\n",
    "    print(\"DATASET OVERVIEW:\")\n",
    "    overview = summary_stats['dataset_overview']\n",
    "    print(f\"Total Observations: {overview['total_observations']}\")\n",
    "    print(f\"Unique Registers: {overview['unique_registers']}\")\n",
    "    print(f\"Unique Variants: {overview['unique_variants']}\")\n",
    "    print(f\"Unique Academic Fields: {overview['unique_fields']}\")\n",
    "    \n",
    "    # Category Proportions\n",
    "    print(\"\\nCATEGORY DISTRIBUTIONS:\")\n",
    "    for category, proportions in summary_stats['category_proportions'].items():\n",
    "        print(f\"\\n{category.upper()}:\")\n",
    "        for item, percentage in proportions.items():\n",
    "            print(f\"  {item}: {percentage:.1f}%\")\n",
    "    \n",
    "    # Usage Statistics\n",
    "    print(\"\\nUSAGE STATISTICS BY REGISTER:\")\n",
    "    usage_stats = summary_stats['usage_statistics']\n",
    "    for metric in usage_stats.keys():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        for register, value in usage_stats[metric].items():\n",
    "            print(f\"  {register}: {value:.2f}\")\n",
    "    \n",
    "    print(\"\\n=== END OF SUMMARY ===\")\n",
    "\n",
    "def main():\n",
    "    # Load and analyze data\n",
    "    df = load_and_clean_data('sociolinguistic_data.csv')\n",
    "    \n",
    "    # Perform analyses\n",
    "    register_analysis = analyze_register_distribution(df)\n",
    "    variant_analysis = analyze_variant_patterns(df)\n",
    "    usage_analysis = analyze_usage_patterns(df)\n",
    "    \n",
    "    # Perform statistical tests\n",
    "    register_variant_test = chi_square_test(df, 'register type', 'variant type')\n",
    "    register_gender_test = chi_square_test(df, 'register type', 'gender')\n",
    "    \n",
    "    # Create visualizations\n",
    "    plot_distributions(df)\n",
    "\n",
    "    summary_stats = generate_summary_statistics(df)\n",
    "    print_summary_report(summary_stats)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'register_analysis': register_analysis,\n",
    "        'variant_analysis': variant_analysis,\n",
    "        'usage_analysis': usage_analysis,\n",
    "        'statistical_tests': {\n",
    "            'register_variant': register_variant_test,\n",
    "            'register_gender': register_gender_test\n",
    "        },\n",
    "        'summary_statistics': summary_stats  # Add this line to include summary stats in results\n",
    "\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross_tabulation_tables(df):\n",
    "    \"\"\"\n",
    "    Create detailed cross-tabulation tables for variant analysis across different social and linguistic factors.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input dataframe containing sociolinguistic data\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing various cross-tabulation tables and statistical measures\n",
    "    \"\"\"\n",
    "    tables = {}\n",
    "    \n",
    "    # 1. Basic variant frequency table across all factors\n",
    "    tables['variant_frequencies'] = {\n",
    "        'register': pd.crosstab(df['variant type'], df['register type']),\n",
    "        'academic_field': pd.crosstab(df['variant type'], df['academic field']),\n",
    "        'gender': pd.crosstab(df['variant type'], df['gender'])\n",
    "    }\n",
    "    \n",
    "    # 2. Three-way cross-tabulation\n",
    "    # Variant type × Register type × Gender\n",
    "    tables['three_way'] = pd.crosstab(\n",
    "        [df['variant type'], df['register type']],\n",
    "        df['gender'],\n",
    "        margins=True\n",
    "    )\n",
    "    \n",
    "    # 3. Proportional tables (normalized by row)\n",
    "    tables['proportional'] = {\n",
    "        'register': pd.crosstab(\n",
    "            df['variant type'],\n",
    "            df['register type'],\n",
    "            normalize='index'\n",
    "        ).round(3) * 100,\n",
    "        'academic_field': pd.crosstab(\n",
    "            df['variant type'],\n",
    "            df['academic field'],\n",
    "            normalize='index'\n",
    "        ).round(3) * 100,\n",
    "        'gender': pd.crosstab(\n",
    "            df['variant type'],\n",
    "            df['gender'],\n",
    "            normalize='index'\n",
    "        ).round(3) * 100\n",
    "    }\n",
    "    \n",
    "    # 4. Summary statistics for each variant\n",
    "    variant_summary = df.groupby('variant type').agg({\n",
    "        'actual usage': ['count', 'nunique'],\n",
    "        'register type': 'nunique',\n",
    "        'academic field': 'nunique',\n",
    "        'gender': 'nunique'\n",
    "    })\n",
    "    variant_summary.columns = [\n",
    "        'total_tokens',\n",
    "        'unique_usage_types',\n",
    "        'registers_used',\n",
    "        'fields_used',\n",
    "        'genders_represented'\n",
    "    ]\n",
    "    tables['variant_summary'] = variant_summary\n",
    "    \n",
    "    # 5. Calculate chi-square statistics for independence tests\n",
    "    tables['chi_square_tests'] = {}\n",
    "    factor_pairs = [\n",
    "        ('variant type', 'register type'),\n",
    "        ('variant type', 'academic field'),\n",
    "        ('variant type', 'gender')\n",
    "    ]\n",
    "    \n",
    "    for var1, var2 in factor_pairs:\n",
    "        contingency = pd.crosstab(df[var1], df[var2])\n",
    "        chi2, p_value, dof, expected = stats.chi2_contingency(contingency)\n",
    "        tables['chi_square_tests'][f'{var1}_vs_{var2}'] = {\n",
    "            'chi2': chi2,\n",
    "            'p_value': p_value,\n",
    "            'dof': dof\n",
    "        }\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def print_cross_tabulation_results(tables):\n",
    "    \"\"\"\n",
    "    Print formatted results from the cross-tabulation analysis in a copy-paste friendly format\n",
    "    \n",
    "    Parameters:\n",
    "    tables (dict): The dictionary containing the cross-tabulation tables and statistics\n",
    "    \"\"\"\n",
    "    def format_table(df, title):\n",
    "        \"\"\"Helper function to format tables consistently\"\"\"\n",
    "        # Convert DataFrame to string with consistent formatting\n",
    "        table_str = df.to_string(float_format=lambda x: '{:.2f}'.format(x) if isinstance(x, float) else str(x))\n",
    "        # Add title with appropriate underlining\n",
    "        separator = '=' * len(title)\n",
    "        return f\"{title}\\n{separator}\\n{table_str}\\n\\n\"\n",
    "    \n",
    "    # Create sections with clear separation and consistent formatting\n",
    "    output = []\n",
    "    \n",
    "    # Header\n",
    "    output.append(\"VARIANT DISTRIBUTION ANALYSIS\")\n",
    "    output.append(\"===========================\\n\")\n",
    "    \n",
    "    # 1. Frequency Tables\n",
    "    output.append(\"1. VARIANT FREQUENCIES BY FACTOR\")\n",
    "    output.append(\"-------------------------------\")\n",
    "    for factor, table in tables['variant_frequencies'].items():\n",
    "        title = f\"{factor.upper()} DISTRIBUTION\"\n",
    "        output.append(format_table(table, title))\n",
    "    \n",
    "    # 2. Three-way Cross-tabulation\n",
    "    output.append(\"2. THREE-WAY CROSS-TABULATION (Variant × Register × Gender)\")\n",
    "    output.append(\"-------------------------------------------------------\")\n",
    "    output.append(format_table(tables['three_way'], \"Variant × Register × Gender Distribution\"))\n",
    "    \n",
    "    # 3. Proportional Distributions\n",
    "    output.append(\"3. PROPORTIONAL DISTRIBUTIONS (%)\")\n",
    "    output.append(\"--------------------------------\")\n",
    "    for factor, table in tables['proportional'].items():\n",
    "        title = f\"{factor.upper()} PROPORTIONS\"\n",
    "        output.append(format_table(table, title))\n",
    "    \n",
    "    # 4. Variant Summary Statistics\n",
    "    output.append(\"4. VARIANT SUMMARY STATISTICS\")\n",
    "    output.append(\"--------------------------\")\n",
    "    output.append(format_table(tables['variant_summary'], \"Summary Statistics by Variant\"))\n",
    "    \n",
    "    # 5. Chi-square Test Results\n",
    "    output.append(\"5. CHI-SQUARE TESTS OF INDEPENDENCE\")\n",
    "    output.append(\"----------------------------------\")\n",
    "    chi_square_results = []\n",
    "    for test_name, results in tables['chi_square_tests'].items():\n",
    "        chi_square_results.append(\n",
    "            f\"Test: {test_name}\\n\"\n",
    "            f\"  Chi-square statistic: {results['chi2']:.2f}\\n\"\n",
    "            f\"  p-value: {results['p_value']:.4f}\\n\"\n",
    "            f\"  Degrees of freedom: {results['dof']}\\n\"\n",
    "            f\"  Significant: {'Yes' if results['p_value'] < 0.05 else 'No'}\\n\"\n",
    "        )\n",
    "    output.append(\"\\n\".join(chi_square_results))\n",
    "    \n",
    "    # Print the formatted output\n",
    "    print(\"\\n\".join(output))\n",
    "\n",
    "def visualize_cross_tabulations(df, tables):\n",
    "    \"\"\"\n",
    "    Create visualizations for the cross-tabulation results\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input dataframe\n",
    "    tables (dict): The dictionary containing the cross-tabulation tables\n",
    "    \n",
    "    Returns:\n",
    "    matplotlib.figure.Figure: The figure containing all plots\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Variant Distribution Across Social and Linguistic Factors', fontsize=16)\n",
    "    \n",
    "    # 1. Heatmap of variant × register frequencies\n",
    "    sns.heatmap(\n",
    "        tables['variant_frequencies']['register'],\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='YlGnBu',\n",
    "        ax=axes[0, 0]\n",
    "    )\n",
    "    axes[0, 0].set_title('Variant Frequencies by Register')\n",
    "    \n",
    "    # 2. Heatmap of variant × academic field frequencies\n",
    "    sns.heatmap(\n",
    "        tables['variant_frequencies']['academic_field'],\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='YlGnBu',\n",
    "        ax=axes[0, 1]\n",
    "    )\n",
    "    axes[0, 1].set_title('Variant Frequencies by Academic Field')\n",
    "    \n",
    "    # 3. Variant summary statistics visualization\n",
    "    tables['variant_summary']['total_tokens'].plot(\n",
    "        kind='bar',\n",
    "        ax=axes[1, 0]\n",
    "    )\n",
    "    axes[1, 0].set_title('Total Tokens by Variant')\n",
    "    axes[1, 0].set_xlabel('Variant Type')\n",
    "    axes[1, 0].set_ylabel('Number of Tokens')\n",
    "    \n",
    "    # 4. Proportional distribution by gender\n",
    "    tables['proportional']['gender'].plot(\n",
    "        kind='bar',\n",
    "        stacked=True,\n",
    "        ax=axes[1, 1]\n",
    "    )\n",
    "    axes[1, 1].set_title('Variant Distribution by Gender (%)')\n",
    "    axes[1, 1].set_xlabel('Variant Type')\n",
    "    axes[1, 1].set_ylabel('Percentage')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANT DISTRIBUTION ANALYSIS\n",
      "===========================\n",
      "\n",
      "1. VARIANT FREQUENCIES BY FACTOR\n",
      "-------------------------------\n",
      "REGISTER DISTRIBUTION\n",
      "=====================\n",
      "register type  Academic  Casual\n",
      "variant type                   \n",
      "Discourse            17      17\n",
      "Lexical              17      17\n",
      "Syntactic            16      16\n",
      "\n",
      "\n",
      "ACADEMIC_FIELD DISTRIBUTION\n",
      "===========================\n",
      "academic field  Anthropology  Bio  CS  Chemistry  Economics  English  Math  Philosophy  Physics  Psychology  Sociology  math  social studies\n",
      "variant type                                                                                                                                \n",
      "Discourse                  0    6   2          2          4        4     1           0        4           0          2     5               4\n",
      "Lexical                    2    2   4          0          2        4     0           8        2           2          4     2               2\n",
      "Syntactic                  6    2   2          8          2        0     0           0        2           6          2     0               2\n",
      "\n",
      "\n",
      "GENDER DISTRIBUTION\n",
      "===================\n",
      "gender         F   M\n",
      "variant type        \n",
      "Discourse     16  18\n",
      "Lexical       18  16\n",
      "Syntactic     16  16\n",
      "\n",
      "\n",
      "2. THREE-WAY CROSS-TABULATION (Variant × Register × Gender)\n",
      "-------------------------------------------------------\n",
      "Variant × Register × Gender Distribution\n",
      "========================================\n",
      "gender                       F   M  All\n",
      "variant type register type             \n",
      "Discourse    Academic        8   9   17\n",
      "             Casual          8   9   17\n",
      "Lexical      Academic        9   8   17\n",
      "             Casual          9   8   17\n",
      "Syntactic    Academic        8   8   16\n",
      "             Casual          8   8   16\n",
      "All                         50  50  100\n",
      "\n",
      "\n",
      "3. PROPORTIONAL DISTRIBUTIONS (%)\n",
      "--------------------------------\n",
      "REGISTER PROPORTIONS\n",
      "====================\n",
      "register type  Academic  Casual\n",
      "variant type                   \n",
      "Discourse         50.00   50.00\n",
      "Lexical           50.00   50.00\n",
      "Syntactic         50.00   50.00\n",
      "\n",
      "\n",
      "ACADEMIC_FIELD PROPORTIONS\n",
      "==========================\n",
      "academic field  Anthropology   Bio    CS  Chemistry  Economics  English  Math  Philosophy  Physics  Psychology  Sociology  math  social studies\n",
      "variant type                                                                                                                                   \n",
      "Discourse               0.00 17.60  5.90       5.90      11.80    11.80  2.90        0.00    11.80        0.00       5.90 14.70           11.80\n",
      "Lexical                 5.90  5.90 11.80       0.00       5.90    11.80  0.00       23.50     5.90        5.90      11.80  5.90            5.90\n",
      "Syntactic              18.80  6.20  6.20      25.00       6.20     0.00  0.00        0.00     6.20       18.80       6.20  0.00            6.20\n",
      "\n",
      "\n",
      "GENDER PROPORTIONS\n",
      "==================\n",
      "gender           F     M\n",
      "variant type            \n",
      "Discourse    47.10 52.90\n",
      "Lexical      52.90 47.10\n",
      "Syntactic    50.00 50.00\n",
      "\n",
      "\n",
      "4. VARIANT SUMMARY STATISTICS\n",
      "--------------------------\n",
      "Summary Statistics by Variant\n",
      "=============================\n",
      "              total_tokens  unique_usage_types  registers_used  fields_used  genders_represented\n",
      "variant type                                                                                    \n",
      "Discourse               34                  33               2           10                    2\n",
      "Lexical                 34                  33               2           11                    2\n",
      "Syntactic               32                  32               2            9                    2\n",
      "\n",
      "\n",
      "5. CHI-SQUARE TESTS OF INDEPENDENCE\n",
      "----------------------------------\n",
      "Test: variant type_vs_register type\n",
      "  Chi-square statistic: 0.00\n",
      "  p-value: 1.0000\n",
      "  Degrees of freedom: 2\n",
      "  Significant: No\n",
      "\n",
      "Test: variant type_vs_academic field\n",
      "  Chi-square statistic: 60.25\n",
      "  p-value: 0.0001\n",
      "  Degrees of freedom: 24\n",
      "  Significant: Yes\n",
      "\n",
      "Test: variant type_vs_gender\n",
      "  Chi-square statistic: 0.24\n",
      "  p-value: 0.8890\n",
      "  Degrees of freedom: 2\n",
      "  Significant: No\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4p/n886yd3s3513z05rpt3f5wgm0000gn/T/ipykernel_39110/2443166016.py:48: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  variant_summary = df.groupby('variant type').agg({\n"
     ]
    }
   ],
   "source": [
    "df  = load_and_clean_data('sociolinguistic_data.csv')\n",
    "cross_tab_tables = create_cross_tabulation_tables(df)\n",
    "print_cross_tabulation_results(cross_tab_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Harvard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
