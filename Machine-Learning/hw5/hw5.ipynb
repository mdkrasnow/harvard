{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CS 1810 Homework 5**\n",
    "---\n",
    "To account for potential version issues, try the following in your terminal:\n",
    "\n",
    "1. Create a new environment with `python3 -m venv venv`\n",
    "2. Activate that environment with `source venv/bin/activate`\n",
    "3. Make sure the interpreter in the top right corner of your VSCode (or whatever you use to run your code is venv).\n",
    "4. If you get a \"install kernel\" message, press it.\n",
    "5. Run `pip install -r requirements.txt`\n",
    "6. Run the remainder of this notebook.\n",
    "\n",
    "Note that this is not necessary but can help prevent any issues due to package versions.\n",
    "\n",
    "**The following notebook is meant to help you work through Problems 2 and 3 on Homework 5. You are by no means required to use it, nor are you required to fill out/use any of the boilerplate code/functions. You are welcome to implement the functions however you wish.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize data and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a specific example of when we have $K = 3$ component Gamma distributions. Let's initialize the initial parameter values for $\\theta$ and $\\beta_k$ as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\theta_k &=  1/K, \\\\\n",
    "  \\beta_k & = k/K.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Note that we usually initialize $\\theta$ and $\\beta_k$ randomly. However, by fixing the initial $\\theta$ and $\\beta_k$, EM becomes deterministic which makes debugging (and grading) easier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as ds\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "x = torch.load('data.pt').reshape((-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "# # uncomment to use numpy (optional)\n",
    "# import numpy as np\n",
    "# from scipy.stats import gamma\n",
    "# x = x.numpy()\n",
    "# theta = theta.numpy()\n",
    "# betas = betas.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "x = x.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement the E-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(theta, betas):\n",
    "    log_px_z = ds.Gamma(alpha, betas).log_prob(x.unsqueeze(1))\n",
    "    # add log theta_k\n",
    "    log_joint = log_px_z + torch.log(theta)\n",
    "    log_sum = torch.logsumexp(log_joint, dim=1, keepdim=True)\n",
    "    q = torch.exp(log_joint - log_sum) \n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement the M-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(q):\n",
    "    N = q.shape[0]\n",
    "    theta_new = q.sum(dim=0) / N\n",
    "    # numerator: alpha * sum_n q[n,k]\n",
    "    # denominator: sum_n q[n,k] * x[n]\n",
    "    weighted_x = (q * x.unsqueeze(1)).sum(dim=0)\n",
    "    betas_new = alpha * q.sum(dim=0) / weighted_x\n",
    "    return theta_new, betas_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_px(x, theta, betas):\n",
    "    x_flat = x.flatten()\n",
    "    log_px_z = ds.Gamma(alpha, betas).log_prob(x_flat.unsqueeze(1))\n",
    "    return torch.logsumexp(log_px_z + torch.log(theta), dim=1)\n",
    "\n",
    "def log_likelihood(theta, betas):\n",
    "    return log_px(x, theta, betas).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_em(theta, betas, iterations=1000, verbose=True):\n",
    "    theta = theta.clone()\n",
    "    betas = betas.clone()\n",
    "    for i in range(iterations):\n",
    "        q = e_step(theta, betas)\n",
    "        theta, betas = m_step(q)\n",
    "        if verbose:\n",
    "            ll = log_likelihood(theta, betas)\n",
    "            print(f'iter {i:4d}, log-likelihood = {ll:.6f}')\n",
    "    return theta, betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overlay_plot(theta, betas):\n",
    "    x_test = torch.linspace(0.01, x.max(), 1000)\n",
    "    prob = log_px(x_test.unsqueeze(-1), theta, betas).exp()\n",
    "    # prob = np.exp(log_px(x_test.unsqueeze(-1), theta, betas))  # use this line for numpy\n",
    "    ll = log_likelihood(theta, betas)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5, 3))\n",
    "    fig.subplots_adjust(top=0.7)\n",
    "    fig.suptitle(f'theta = {theta}\\nbeta = {betas}\\nlog likelihood = {ll:.3e}')\n",
    "    \n",
    "    ax.hist(x, bins=100, color='tomato', alpha=0.5, density=True, label='Dataset')\n",
    "    ax.plot(x_test, prob, color='royalblue', label='Gamma mixture')\n",
    "    \n",
    "    ax.set_title(f'Dataset and Gamma mixture (K={len(theta)})')\n",
    "    ax.set_xlabel('Recovery time (hours)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 5.0\n",
    "for K in range(1,5):\n",
    "    theta0 = torch.ones(K) / K\n",
    "    betas0 = (torch.arange(K) + 1) / K\n",
    "    theta, betas = run_em(theta0, betas0, verbose=False)\n",
    "    make_overlay_plot(theta, betas)\n",
    "    plt.savefig(f'img_output/p2_3_{K}mixtures.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 19.7MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.75MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.3MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.00MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "mnist_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)  # download MNIST\n",
    "N = 6000 \n",
    "\n",
    "x = mnist_trainset.data[:N]  # select N datapoints\n",
    "x = x.flatten(1)             # flatten the images\n",
    "x = x.float()                # convert pixels from uint8 to float\n",
    "# x = x.numpy()              # uncomment to use numpy (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement PCA\n",
    "\n",
    "*Hint: see `.linalg.svd()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(x, n_comps=500):\n",
    "    x_mean = x.mean(dim=0)\n",
    "    Xc = x - x_mean\n",
    "    U, S, Vh = torch.linalg.svd(Xc, full_matrices=False)\n",
    "    eigvals = (S**2) / (x.shape[0] - 1)\n",
    "    return eigvals[:n_comps], Vh[:n_comps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** calculate cumulative fraction of variance\n",
    "\n",
    "*Hint: see `.cumsum()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cfvs(eigvals):\n",
    "    cfvs = eigvals.cumsum(dim=0) / eigvals.sum()\n",
    "    return cfvs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** calculate mean squared L2 norm reconstruction losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_errs(x, pcomps, n_pcs=10):\n",
    "    x_mean = x.mean(dim=0)\n",
    "    err_mean = ((x - x_mean)**2).sum(dim=1).mean().item()\n",
    "    pcs = pcomps[:n_pcs]                # [n_pcs, D]\n",
    "    Xc = x - x_mean                     # [N, D]\n",
    "    coeffs = Xc @ pcs.T                 # [N, n_pcs]\n",
    "    x_recon = x_mean + coeffs @ pcs     # [N, D]\n",
    "    err_pcomp = ((x - x_recon)**2).sum(dim=1).mean().item()\n",
    "    return err_mean, err_pcomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and print errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pic(pic, ax, title=''):\n",
    "    x = pic.reshape(28, 28)\n",
    "    ax.imshow(x, cmap='binary')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "def make_plots(eigvals, cfvs, x_mean, pcomps):\n",
    "    # plot eigenvals and cfvs\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "    ax1.plot(eigvals, color='tomato')\n",
    "    ax1.set_title('Eigenvalues')\n",
    "    ax2.plot(cfvs, color='tomato')\n",
    "    ax2.set_title('CFVs')\n",
    "    fig.savefig('img_output/p3_cfvs.pdf')\n",
    "\n",
    "    # plot mean\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "    plot_pic(x_mean, ax, title='Mean')\n",
    "    fig.savefig('img_output/p3_mean.pdf')\n",
    "\n",
    "    # plot top 10 pcomps\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "    for i in range(10):\n",
    "        plot_pic(pcomps[i], axes.flat[i], title=f'PC index {i}')\n",
    "    fig.savefig('img_output/p3_pcomps.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error (using mean): 3.436024e+06\n",
      "Reconstruction error (using mean and top 10 pcomps): 1.731315e+06\n"
     ]
    }
   ],
   "source": [
    "# do PCA\n",
    "eigvals, pcomps = pca(x)\n",
    "\n",
    "# calculate CFVs\n",
    "fcvs = calc_cfvs(eigvals)\n",
    "\n",
    "# print errors\n",
    "err_mean, err_pcomp = calc_errs(x, pcomps)\n",
    "print(f'Reconstruction error (using mean): {err_mean:3e}')  # 3.436022e+06\n",
    "print(f'Reconstruction error (using mean and top 10 pcomps): {err_pcomp:3e}')  # 1.731315e+06\n",
    "\n",
    "# make plots\n",
    "make_plots(eigvals, fcvs, x.mean(0), pcomps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Harvard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
